{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建图像生成应用程序\n",
    "\n",
    "LLM不仅可以用于文本生成，还可以从文本描述中生成图像。在医疗科技、建筑、旅游、游戏开发等领域中，图像作为一种形态可以极大地提高效率。在本章中，我们将介绍两种最流行的图像生成模型，DALL-E 和 Midjourney。\n",
    "\n",
    "## 介绍\n",
    "\n",
    "在本课程中，我们将涵盖以下内容：\n",
    "\n",
    "- 图像生成及其有用之处。\n",
    "- DALL-E 和 Midjourney，它们是什么以及如何工作。\n",
    "- 如何构建图像生成应用程序。\n",
    "\n",
    "## 学习目标\n",
    "\n",
    "完成本课程后，您将能够：\n",
    "\n",
    "- 构建图像生成应用程序。\n",
    "- 用元提示为您的应用程序定义边界。\n",
    "- 使用 DALL-E 和 Midjourney。\n",
    "\n",
    "## 为什么构建图像生成应用程序？\n",
    "\n",
    "图像生成应用程序是探索生成式人工智能能力的绝佳方式。例如，它们可用于：\n",
    "\n",
    "- **图像编辑和合成**。您可以生成用于各种用途的图像，如图像编辑和图像合成。\n",
    "\n",
    "- **应用于各种行业**。它们还可用于为医疗科技、旅游、游戏开发等各种行业生成图像。\n",
    "\n",
    "## 场景：Edu4All\n",
    "\n",
    "作为本课程的一部分，我们将继续与我们的初创公司Edu4All合作。在本课程中，学生们将为他们的评估创建图像，具体创建哪些图像是由学生决定的，但可以是他们自己童话的插图，或者为他们的故事创作新角色，或者帮助他们展示他们的想法和概念。\n",
    "\n",
    "例如，这是Edu4All的学生们可以生成的示例，如果他们在课堂上学习纪念碑：\n",
    "\n",
    "![Edu4All初创公司，纪念碑课程，埃菲尔铁塔](../images/startup.png?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "使用类似以下提示的提示语：\n",
    "\n",
    ">\"清晨阳光下埃菲尔铁塔旁的狗\"\n",
    "\n",
    "## 什么是 DALL-E 和 Midjourney？\n",
    "\n",
    "[DALL-E](https://openai.com/dall-e-2?WT.mc_id=academic-105485-koreyst) 和 [Midjourney](https://www.midjourney.com/?WT.mc_id=academic-105485-koreyst) 是两个最流行的图像生成模型，它们允许您使用提示语生成图像。\n",
    "\n",
    "### DALL-E\n",
    "\n",
    "让我们从 DALL-E 开始，它是一种生成式人工智能模型，可以从文本描述中生成图像。\n",
    "\n",
    "> [DALL-E 是 CLIP 和扩散注意力两个模型的组合](https://towardsdatascience.com/openais-dall-e-and-clip-101-a-brief-introduction-3a4367280d4e?WT.mc_id=academic-105485-koreyst)。\n",
    "\n",
    "- **CLIP** 是一个能够从图像和文本中生成嵌入式（数据的数值表示）的模型。\n",
    "\n",
    "- **扩散注意力** 是一个能够从嵌入式生成图像的模型。DALL-E 受过图像和文本数据集的训练，并可用于根据文本描述生成图像。例如，DALL-E 可用于生成戴帽子的猫的图像，或者带着莫霍克发型的狗的图像。\n",
    "\n",
    "### Midjourney\n",
    "\n",
    "Midjourney 与 DALL-E 的工作方式类似，它也可以根据文本提示生成图像。Midjourney 也可以用于使用像“戴帽子的猫”或“带着莫霍克发型的狗”这样的提示生成图像。\n",
    "\n",
    "![Midjourney 生成的图像，机械鸽子](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png/440px-Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "*图像来源：维基百科，由 Midjourney 生成*\n",
    "\n",
    "## DALL-E 和 Midjourney 的工作原理\n",
    "\n",
    "首先，[DALL-E](https://arxiv.org/pdf/2102.12092.pdf?WT.mc_id=academic-105485-koreyst)。DALL-E 是一个基于变压器架构和*自回归变压器*的生成式人工智能模型。\n",
    "\n",
    "*自回归变压器* 定义了模型如何从文本描述生成图像，它一次生成一个像素，然后使用生成的像素生成下一个像素，依次经过神经网络中的多个层，直到图像完成。\n",
    "\n",
    "通过这个过程，DALL-E 可以控制所生成图像的属性、对象、特征等。然而，DALL-E 2 和 3 对生成图像有更多的控制权。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建您的第一个图像生成应用程序\n",
    "\n",
    "那么构建图像生成应用程序需要哪些库呢？您需要以下库：\n",
    "\n",
    "- **python-dotenv**，强烈建议您使用此库将您的机密信息存储在 *.env* 文件中，远离代码。\n",
    "- **openai**，这个库是您将用于与 OpenAI API 进行交互的工具。\n",
    "- **pillow**，用于在Python中处理图像。\n",
    "- **requests**，帮助您进行HTTP请求。\n",
    "\n",
    "1. 创建一个名为 *.env* 的文件，并添加以下内容：\n",
    "\n",
    "    ```text\n",
    "    AZURE_OPENAI_ENDPOINT=<your endpoint>\n",
    "    AZURE_OPENAI_KEY=<your key>\n",
    "    ```\n",
    "\n",
    "    在 Azure 门户中，您可以在资源的 “Keys and Endpoint” 部分找到这些信息。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```markdown\n",
    "1. 将上述库收集在名为*requirements.txt*的文件中，如下所示：\n",
    "\n",
    "    ```text\n",
    "    python-dotenv\n",
    "    openai\n",
    "    pillow\n",
    "    requests\n",
    "    ```\n",
    "\n",
    "1. 接下来，创建虚拟环境并安装这些库：\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create virtual env\n",
    "! python3 -m venv venv\n",
    "# activate environment\n",
    "! source venv/bin/activate\n",
    "# install libraries\n",
    "# pip install -r requirements.txt, if using a requirements.txt file \n",
    "! pip install python-dotenv openai pillow requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> 对于 Windows 操作系统，请使用以下命令来创建和激活您的虚拟环境：\n",
    "\n",
    "    ```bash\n",
    "    python3 -m venv venv\n",
    "    venv\\Scripts\\activate.bat\n",
    "    ````\n",
    "    \n",
    "1. 将以下代码添加到名为 *app.py* 的文件中：\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "    \n",
    "    # 导入 dotenv 库\n",
    "    dotenv.load_dotenv()\n",
    "    \n",
    "    # 从环境变量中获取终结点和密钥\n",
    "    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "    openai.api_key = os.environ['AZURE_OPENAI_KEY']     \n",
    "    \n",
    "    # 指定 API 版本（DALL-E 目前仅支持 2023-06-01-preview API 版本）\n",
    "    openai.api_version = '2023-06-01-preview'\n",
    "    openai.api_type = 'azure'\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # 使用图像生成 API 创建一个图像\n",
    "        generation_response = openai.Image.create(\n",
    "            prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # 在此处输入您的提示词\n",
    "            size='1024x1024',\n",
    "            n=2,\n",
    "            temperature=0,\n",
    "        )\n",
    "        # 设置存储图像的目录\n",
    "        image_dir = os.path.join(os.curdir, 'images')\n",
    "    \n",
    "        # 如果目录不存在，则创建它\n",
    "        if not os.path.isdir(image_dir):\n",
    "            os.mkdir(image_dir)\n",
    "    \n",
    "        # 初始化图像路径（注意文件类型应为 png）\n",
    "        image_path = os.path.join(image_dir, 'generated-image.png')\n",
    "    \n",
    "        # 检索生成的图像\n",
    "        image_url = generation_response[\"data\"][0][\"url\"]  # 从响应中提取图像 URL\n",
    "        generated_image = requests.get(image_url).content  # 下载图像\n",
    "        with open(image_path, \"wb\") as image_file:\n",
    "            image_file.write(generated_image)\n",
    "    \n",
    "        # 在默认图像查看器中显示图像\n",
    "        image = Image.open(image_path)\n",
    "        image.show()\n",
    "    \n",
    "    # 捕获异常\n",
    "    except openai.error.InvalidRequestError as err:\n",
    "        print(err)\n",
    "\n",
    "    ```\n",
    "\n",
    "让我们解释一下这段代码：\n",
    "\n",
    "- 首先，我们导入所需的库，其中包括 OpenAI 库、dotenv 库、requests 库和 Pillow 库。\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "    ```\n",
    "\n",
    "- 接下来，我们从 *.env* 文件中加载环境变量。\n",
    "\n",
    "    ```python\n",
    "    # 导入 dotenv 库\n",
    "    dotenv.load_dotenv()\n",
    "    ```\n",
    "\n",
    "- 然后，我们设置了 OpenAI API 的终结点、密钥、版本和类型。\n",
    "\n",
    "    ```python\n",
    "    # 从环境变量中获取终结点和密钥\n",
    "    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "    openai.api_key = os.environ['AZURE_OPENAI_KEY'] \n",
    "\n",
    "    # 添加版本和类型，适用于 Azure\n",
    "    openai.api_version = '2023-06-01-preview'\n",
    "    openai.api_type = 'azure'\n",
    "    ```\n",
    "\n",
    "- 接下来，我们生成了图像：\n",
    "\n",
    "    ```python\n",
    "    # 使用图像生成 API 创建一个图像\n",
    "    generation_response = openai.Image.create(\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # 在此处输入您的提示词\n",
    "        size='1024x1024',\n",
    "        n=2,\n",
    "        temperature=0,\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    以上代码将返回一个包含生成图像的 URL 的 JSON 对象。我们可以使用该 URL 下载图像并将其保存到文件中。\n",
    "\n",
    "- 最后，我们打开图像并使用标准的图像查看器显示它：\n",
    "\n",
    "    ```python\n",
    "    image = Image.open(image_path)\n",
    "    image.show()\n",
    "    ```\n",
    "\n",
    "### 关于生成图像的更多细节\n",
    "\n",
    "让我们更详细地看一下生成图像的代码：\n",
    "\n",
    "```python\n",
    "generation_response = openai.Image.create(\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # 在此处输入您的提示词\n",
    "        size='1024x1024',\n",
    "        n=2,\n",
    "        temperature=0,\n",
    "    )\n",
    "```\n",
    "\n",
    "- **prompt** 是用于生成图像的文本提示。在本例中，我们使用提示词 \"Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils\"。\n",
    "- **size** 是生成图像的尺寸。在本例中，我们生成了一个大小为 1024x1024 像素的图像。\n",
    "- **n** 是生成的图像数量。在本例中，我们生成了两张图像。\n",
    "- **temperature** 是一个控制生成式人工智能模型输出随机性的参数。温度是一个介于 0 和 1 之间的值，其中 0 表示输出是确定性的，而 1 表示输出是随机的。默认值为 0.7。\n",
    "\n",
    "还有更多关于图像的操作方式，我们将在下一节进行介绍。\n",
    "\n",
    "## 图像生成的额外功能\n",
    "\n",
    "到目前为止，您已经了解了我们是如何使用几行 Python 代码生成图像的。然而，您还可以做更多有关图像的事情。\n",
    "\n",
    "您还可以进行以下操作：\n",
    "\n",
    "- **执行编辑**。通过提供现有图像、一个蒙版和一个提示词，您可以改变图像。例如，您可以向图像的某个部分添加东西。想象一下我们的兔子图像，您可以给兔子加上一顶帽子。您可以通过提供图像、一个蒙版（确定更改区域的部分）和一个文本提示来实现这一点。\n",
    "\n",
    "    ```python\n",
    "    response = openai.Image.create_edit(\n",
    "      image=open(\"base_image.png\", \"rb\"),\n",
    "      mask=open(\"mask.png\", \"rb\"),\n",
    "      prompt=\"An image of a rabbit with a hat on its head.\",\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response['data'][0]['url']\n",
    "    ```\n",
    "\n",
    "    基本图像只包含兔子，但最终图像会在兔子头上带上帽子。\n",
    "\n",
    "- **创建变体**。 \n",
    "    查看我们的[OpenAI 笔记本](/09-building-image-applications/openai/notebook-openai.ipynb)以获取更多信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "from openai import AzureOpenAI\n",
    "import os\n",
    "import requests\n",
    "from PIL import Image\n",
    "import dotenv\n",
    "import json\n",
    "\n",
    "# import dotenv\n",
    "dotenv.load_dotenv()\n",
    "\n",
    " \n",
    "\n",
    "# Assign the API version (DALL-E is currently supported for the 2023-06-01-preview API version only)\n",
    "client = AzureOpenAI(\n",
    "  api_key=os.environ['AZURE_OPENAI_KEY'],  # this is also the default, it can be omitted\n",
    "  api_version = \"2023-12-01-preview\",\n",
    "  azure_endpoint=os.environ['AZURE_OPENAI_ENDPOINT'] \n",
    "  )\n",
    "\n",
    "model = os.environ['AZURE_OPENAI_DEPLOYMENT']\n",
    "\n",
    "disallow_list = \"swords, violence, blood, gore, nudity, sexual content, adult content, adult themes, adult language, adult humor, adult jokes, adult situations, adult\"\n",
    "\n",
    "meta_prompt = f\"\"\"You are an assistant designer that creates images for children. \n",
    "\n",
    "The image needs to be safe for work and appropriate for children. \n",
    "\n",
    "The image needs to be in color.  \n",
    "\n",
    "The image needs to be in landscape orientation.  \n",
    "\n",
    "The image needs to be in a 16:9 aspect ratio. \n",
    "\n",
    "Do not consider any input from the following that is not safe for work or appropriate for children. \n",
    "{disallow_list}\"\"\"\n",
    "\n",
    "prompt = f\"\"\"{meta_prompt}\n",
    "Generate monument of the Arc of Triumph in Paris, France, in the evening light with a small child holding a Teddy looks on.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "try:\n",
    "    # Create an image by using the image generation API\n",
    "\n",
    "    result = client.images.generate(\n",
    "        model=model,\n",
    "        prompt=prompt,    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=1\n",
    "    )\n",
    "\n",
    "    generation_response = json.loads(result.model_dump_json())\n",
    "    # Set the directory for the stored image\n",
    "    image_dir = os.path.join(os.curdir, 'images')\n",
    "\n",
    "    # If the directory doesn't exist, create it\n",
    "    if not os.path.isdir(image_dir):\n",
    "        os.mkdir(image_dir)\n",
    "\n",
    "    # Initialize the image path (note the filetype should be png)\n",
    "    image_path = os.path.join(image_dir, 'ch9-sol-generated-image.png')\n",
    "\n",
    "    # Retrieve the generated image\n",
    "    image_url = generation_response[\"data\"][0][\"url\"]  # extract image URL from response\n",
    "    generated_image = requests.get(image_url).content  # download the image\n",
    "    with open(image_path, \"wb\") as image_file:\n",
    "        image_file.write(generated_image)\n",
    "\n",
    "    # Display the image in the default image viewer\n",
    "    image = Image.open(image_path)\n",
    "    image.show()\n",
    "\n",
    "# catch exceptions\n",
    "#except client.error.InvalidRequestError as err:\n",
    "#    print(err)\n",
    "\n",
    "finally:\n",
    "    print(\"completed!\")\n",
    "# ---creating variation below---\n",
    "\n",
    "\n",
    "\n",
    "# response = openai.Image.create_variation(\n",
    "#   image=open(image_path, \"rb\"),\n",
    "#   n=1,\n",
    "#   size=\"1024x1024\"\n",
    "# )\n",
    "\n",
    "# image_path = os.path.join(image_dir, 'generated_variation.png')\n",
    "\n",
    "# image_url = response['data'][0]['url']\n",
    "\n",
    "# generated_image = requests.get(image_url).content  # download the image\n",
    "# with open(image_path, \"wb\") as image_file:\n",
    "#     image_file.write(generated_image)\n",
    "\n",
    "# # Display the image in the default image viewer\n",
    "# image = Image.open(image_path)\n",
    "# image.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
