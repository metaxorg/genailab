{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了运行以下笔记本，如果您还没有这样做，您需要部署一个使用 `text-embedding-ada-002` 作为基础模型的模型，并在 .env 文件中将部署名称设置为 `AZURE_OPENAI_EMBEDDINGS_ENDPOINT`。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key=os.environ['AZURE_OPENAI_KEY'],  # this is also the default, it can be omitted\n",
    "  api_version = \"2023-05-15\"\n",
    "  )\n",
    "\n",
    "model = os.environ['AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT']\n",
    "\n",
    "SIMILARITIES_RESULTS_THRESHOLD = 0.75\n",
    "DATASET_NAME = \"../embedding_index_3m.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们要将嵌入索引加载到Pandas Dataframe中。嵌入索引存储在名为`embedding_index_3m.json`的JSON文件中。嵌入索引包含了截至2023年10月底的每个YouTube转录的嵌入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    # Load the video session index\n",
    "    pd_vectors = pd.read_json(source)\n",
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们将创建一个名为 `get_videos` 的函数，该函数将搜索嵌入索引以寻找查询。该函数将返回与查询最相似的前5个视频。函数的工作如下：\n",
    "\n",
    "1. 首先，创建嵌入索引的副本。\n",
    "2. 接下来，使用 OpenAI 嵌入 API 计算查询的嵌入。\n",
    "3. 然后在嵌入索引中创建一个名为 `similarity` 的新列。`similarity` 列包含查询嵌入和每个视频片段嵌入之间的余弦相似度。\n",
    "4. 接下来，通过 `similarity` 列对嵌入索引进行过滤。嵌入索引将被过滤，只包括余弦相似度大于或等于0.75的视频。\n",
    "5. 最后，嵌入索引将根据 `similarity` 列进行排序，并返回前5个视频。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    # create a copy of the dataset\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    # get the embeddings for the query    \n",
    "    query_embeddings = client.embeddings.create(input=query, model=model).data[0].embedding\n",
    "\n",
    "    # create a new column with the calculated similarity for each row\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # filter the videos by similarity\n",
    "    mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD\n",
    "    video_vectors = video_vectors[mask].copy()\n",
    "\n",
    "    # sort the videos by similarity\n",
    "    video_vectors = video_vectors.sort_values(by=\"similarity\", ascending=False).head(\n",
    "        rows\n",
    "    )\n",
    "\n",
    "    # return the top rows\n",
    "    return video_vectors.head(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个函数非常简单，它只是打印出搜索查询的结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"convert time in format 00:00:00 to seconds\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nVideos similar to '{query}':\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Summary: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Similarity: {row['similarity']}\")\n",
    "        print(f\"   Speakers: {row['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 首先，将嵌入索引加载到Pandas Dataframe中。\n",
    "2. 接下来，提示用户输入查询。\n",
    "3. 然后调用`get_videos`函数来搜索嵌入索引中的查询。\n",
    "4. 最后，调用`display_results`函数来向用户显示结果。\n",
    "5. 然后提示用户输入另一个查询。这个过程会一直持续，直到用户输入“exit”。\n",
    "\n",
    "![](media/notebook_search.png)\n",
    "\n",
    "您将被提示输入查询。输入查询并按回车键。应用程序将返回与查询相关的视频列表。该应用程序还将返回视频中回答问题的位置链接。\n",
    "\n",
    "以下是一些可尝试的查询：\n",
    "\n",
    "- 什么是Azure机器学习？\n",
    "- 卷积神经网络是如何工作的？\n",
    "- 什么是神经网络？\n",
    "- 我可以在Azure机器学习中使用Jupyter Notebooks吗？\n",
    "- 什么是ONNX？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_vectors = load_dataset(DATASET_NAME)\n",
    "\n",
    "# get user query from imput\n",
    "while True:\n",
    "    query = input(\"Enter a query: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    videos = get_videos(query, pd_vectors, 5)\n",
    "    display_results(videos, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welcome to our Markdown Translator\n",
    "\n",
    "This tool allows you to translate Markdown content from English to Simplified Chinese. Simply input your content and we will handle the translation for you. If you have any **prompts or requirements**, please feel free to let us know.\n",
    "\n",
    "Start translating by providing the content you'd like to be translated."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
