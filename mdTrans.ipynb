{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#初始化\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "#pypandoc.download_pandoc()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key = \"0ac58578134f428885682a58a596a569\",  \n",
    "  api_version = \"2023-05-15\",\n",
    "  azure_endpoint = \"https://haxudalle.openai.azure.com/\"\n",
    ")\n",
    "\n",
    "# 设置openai API默认参数, name = gpt-35-turbo-1106\n",
    "def get_completion(prompt): \n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"\"\"\n",
    "         Translate this markdown content to Simplified Chinese. Follow the below rules:\n",
    "         1. Must keep original markdown format and position. \n",
    "         2. Do not change any markdown or html tags.\n",
    "         3. The expected documentation or material shall keep the integrality of contents.\n",
    "         4. The translated content shall be grammatically correct.\n",
    "         5. The translated content shall be fluent and easy to understand.\n",
    "         6. Must follow the below glossary which between two ###.\n",
    "         ###\n",
    "         prompt:提示\n",
    "         prompts:提示词\n",
    "         prompting:提示词\n",
    "         prompt engeieering:提示工程\n",
    "         zero shot:零示例\n",
    "         one shot:单示例\n",
    "         few shot:少示例\n",
    "         CoT:思维链\n",
    "         ###\n",
    "         \"\"\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    response = client.chat.completions.create(\n",
    "      model=\"gpt-35-turbo\",\n",
    "      #model=\"gpt-4-1106-preview\",\n",
    "      messages=messages\n",
    "      )\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#汉化文件夹中所有md文件\n",
    "def read_markdown_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    return content\n",
    "\n",
    "def save_to_markdown(file_path, content):\n",
    "    base_name = os.path.basename(file_path)\n",
    "    name, ext = os.path.splitext(base_name)\n",
    "    new_name = f\"{name}_chs{ext}\"\n",
    "    new_path = os.path.join(os.path.dirname(file_path), new_name)\n",
    "    with open(new_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(content)\n",
    "\n",
    "def process_and_save_all_markdown_files(directory_path):\n",
    "    processed_files_count = 0\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.md' or '.MD'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                relative_path = os.path.relpath(file_path, directory_path)\n",
    "                print(\"Processing file:\", relative_path)\n",
    "                content = read_markdown_file(file_path)\n",
    "                processed_content = get_completion(content)\n",
    "                save_to_markdown(file_path, processed_content)\n",
    "                processed_files_count += 1\n",
    "    return processed_files_count\n",
    "\n",
    "directory_path = 'labs'\n",
    "processed_files_count = process_and_save_all_markdown_files(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##翻译ipynb文件中的所有markdown单元格\n",
    "import os\n",
    "import nbformat\n",
    "\n",
    "def process_and_save_all_ipynb_files(directory_path):\n",
    "    processed_files_count = 0\n",
    "    for root, dirs, files in os.walk(directory_path):\n",
    "        for file in files:\n",
    "            if file.endswith('.ipynb'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                process_and_save_ipynb(file_path)\n",
    "                processed_files_count += 1\n",
    "    return processed_files_count\n",
    "\n",
    "def process_and_save_ipynb(file_path):\n",
    "    # 读取.ipynb文件\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "\n",
    "    # 遍历所有单元格\n",
    "    for i, cell in enumerate(nb.cells):\n",
    "        # 如果单元格是Markdown类型\n",
    "        if cell.cell_type == 'markdown':\n",
    "            # 使用get_completion函数处理单元格内容\n",
    "            cell.source = get_completion(cell.source)\n",
    "\n",
    "    # 生成新的文件名\n",
    "    base_name = os.path.basename(file_path)\n",
    "    name, ext = os.path.splitext(base_name)\n",
    "    new_name = f\"{name}_chs{ext}\"\n",
    "    new_path = os.path.join(os.path.dirname(file_path), new_name)\n",
    "\n",
    "    # 保存.ipynb文件\n",
    "    with open(new_path, 'w', encoding='utf-8') as f:\n",
    "        nbformat.write(nb, f)\n",
    "\n",
    "# 使用函数\n",
    "directory_path = './test/'\n",
    "processed_files_count = process_and_save_all_ipynb_files(directory_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import (\n",
    "    RecursiveCharacterTextSplitter,\n",
    "    Language,\n",
    ")\n",
    "\n",
    "md_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.MARKDOWN, chunk_size=1000, chunk_overlap=0\n",
    ")\n",
    "\n",
    "def read_markdown_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    return content\n",
    "\n",
    "def save_to_markdown(file_path, content):\n",
    "    with open(file_path, 'a', encoding='utf-8') as f:\n",
    "        f.write(content)\n",
    "\n",
    "file_path = 'moaw\\workshops\\github-copilot\\workshop.md'\n",
    "markdown_text = read_markdown_file(file_path)\n",
    "\n",
    "md_docs = md_splitter.create_documents([markdown_text])\n",
    "\n",
    "for doc in md_docs:\n",
    "    doc.page_content = get_completion(doc.page_content)\n",
    "\n",
    "    # 保存处理后的内容到新的 Markdown 文件\n",
    "    new_file_path = file_path.replace('.md', '_chs.md')\n",
    "    save_to_markdown(new_file_path, doc.page_content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
